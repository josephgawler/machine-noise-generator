{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9742aab5-2bdc-434e-9bdc-0c92f1ecd574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ada40e-b488-4407-82c0-e3ef3a21f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 100\n",
    "SR = 16000  # Sample rate from MIMII dataset\n",
    "AUDIO_LENGTH = 10  # seconds (MIMII contains 10s segments)\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512\n",
    "N_MELS = 128\n",
    "BATCH_SIZE = 8  # Reduced batch size\n",
    "EPOCHS = 2000\n",
    "TIME_DIM = 313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf063611-fa73-49e5-9a14-0a859884e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_audio(file_path, is_abnormal=False):\n",
    "    \"\"\"Load audio file and convert to mel spectrogram\"\"\"\n",
    "    # Load audio file\n",
    "    audio, _ = librosa.load(file_path, sr=SR, duration=AUDIO_LENGTH)\n",
    "    \n",
    "    # Pad if needed\n",
    "    if len(audio) < SR * AUDIO_LENGTH:\n",
    "        audio = np.pad(audio, (0, SR * AUDIO_LENGTH - len(audio)))\n",
    "    elif len(audio) > SR * AUDIO_LENGTH:\n",
    "        audio = audio[:SR * AUDIO_LENGTH]\n",
    "    \n",
    "    # Create mel spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio, \n",
    "        sr=SR, \n",
    "        n_fft=N_FFT, \n",
    "        hop_length=HOP_LENGTH, \n",
    "        n_mels=N_MELS\n",
    "    )\n",
    "    \n",
    "    # Convert to log scale\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec)\n",
    "    \n",
    "    # Normalize\n",
    "    log_mel_spec = (log_mel_spec - log_mel_spec.min()) / (log_mel_spec.max() - log_mel_spec.min())\n",
    "    \n",
    "    # Add channel dimension\n",
    "    log_mel_spec = np.expand_dims(log_mel_spec, axis=-1)\n",
    "    \n",
    "    # Pad to match expected shape if needed\n",
    "    if log_mel_spec.shape[1] < TIME_DIM:\n",
    "        pad_width = ((0, 0), (0, TIME_DIM - log_mel_spec.shape[1]), (0, 0))\n",
    "        log_mel_spec = np.pad(log_mel_spec, pad_width, mode='constant')\n",
    "    elif log_mel_spec.shape[1] > TIME_DIM:\n",
    "        log_mel_spec = log_mel_spec[:, :TIME_DIM, :]\n",
    "    \n",
    "    # Add label for condition (0 for normal, 1 for abnormal)\n",
    "    condition = 1 if is_abnormal else 0\n",
    "    \n",
    "    return log_mel_spec, condition\n",
    "\n",
    "def process_mimii_dataset(base_dir, machine_types=[\"fan\", \"pump\", \"slider\", \"valve\"], machine_ids=[\"00\", \"02\", \"04\", \"06\"]):\n",
    "    \"\"\"Process MIMII dataset files for multiple machine types and IDs\"\"\"\n",
    "    specs = []\n",
    "    conditions = []\n",
    "    \n",
    "    # Process each machine type\n",
    "    for machine_type in machine_types:\n",
    "        print(f\"\\nProcessing {machine_type} data...\")\n",
    "        machine_dir = os.path.join(base_dir, f\"trimmed_{machine_type}\")\n",
    "        \n",
    "        if not os.path.exists(machine_dir):\n",
    "            print(f\"Warning: Directory not found: {machine_dir}\")\n",
    "            continue\n",
    "            \n",
    "        # Process normal samples\n",
    "        normal_base_dir = os.path.join(machine_dir, \"normal\")\n",
    "        if os.path.exists(normal_base_dir):\n",
    "            # Process each machine ID\n",
    "            for machine_id in machine_ids:\n",
    "                normal_id_dir = os.path.join(normal_base_dir, f\"id_{machine_id}\")\n",
    "                if os.path.exists(normal_id_dir):\n",
    "                    normal_files = glob.glob(os.path.join(normal_id_dir, \"*.wav\"))\n",
    "                    \n",
    "                    print(f\"Processing {len(normal_files)} normal files for {machine_type} id_{machine_id}\")\n",
    "                    for file_path in tqdm(normal_files[:50]):  # Limit to 50 files per ID for faster processing\n",
    "                        try:\n",
    "                            spec, condition = load_and_preprocess_audio(file_path, is_abnormal=False)\n",
    "                            specs.append(spec)\n",
    "                            conditions.append(condition)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing {file_path}: {e}\")\n",
    "                else:\n",
    "                    print(f\"Directory not found: {normal_id_dir}\")\n",
    "        else:\n",
    "            print(f\"Normal directory not found: {normal_base_dir}\")\n",
    "            \n",
    "        # Process abnormal samples\n",
    "        abnormal_base_dir = os.path.join(machine_dir, \"abnormal\")\n",
    "        if os.path.exists(abnormal_base_dir):\n",
    "            # Process each machine ID\n",
    "            for machine_id in machine_ids:\n",
    "                abnormal_id_dir = os.path.join(abnormal_base_dir, f\"id_{machine_id}\")\n",
    "                if os.path.exists(abnormal_id_dir):\n",
    "                    abnormal_files = glob.glob(os.path.join(abnormal_id_dir, \"*.wav\"))\n",
    "                    \n",
    "                    print(f\"Processing {len(abnormal_files)} abnormal files for {machine_type} id_{machine_id}\")\n",
    "                    for file_path in tqdm(abnormal_files[:50]):  # Limit to 50 files per ID for faster processing\n",
    "                        try:\n",
    "                            spec, condition = load_and_preprocess_audio(file_path, is_abnormal=True)\n",
    "                            specs.append(spec)\n",
    "                            conditions.append(condition)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing {file_path}: {e}\")\n",
    "                else:\n",
    "                    print(f\"Directory not found: {abnormal_id_dir}\")\n",
    "        else:\n",
    "            print(f\"Abnormal directory not found: {abnormal_base_dir}\")\n",
    "    \n",
    "    # If no files were found, create some dummy data to avoid errors\n",
    "    if len(specs) == 0:\n",
    "        print(\"WARNING: No files were processed. Creating dummy data for debugging.\")\n",
    "        return np.zeros((10, N_MELS, TIME_DIM, 1)), np.zeros(10)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    specs = np.array(specs)\n",
    "    conditions = np.array(conditions)\n",
    "    \n",
    "    print(f\"Dataset shape: {specs.shape}, Conditions shape: {conditions.shape}\")\n",
    "    \n",
    "    return specs, conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40616911-0339-42ae-8413-fed8d5472692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactOutputSize(layers.Layer):\n",
    "    def __init__(self, target_height, target_width, **kwargs):\n",
    "        super(ExactOutputSize, self).__init__(**kwargs)\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(ExactOutputSize, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, [self.target_height, self.target_width])\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.target_height, self.target_width, input_shape[3])\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(ExactOutputSize, self).get_config()\n",
    "        config.update({\n",
    "            'target_height': self.target_height,\n",
    "            'target_width': self.target_width\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Generator network\n",
    "def build_generator(latent_dim):\n",
    "    \"\"\"Build generator network with conditional input\"\"\"\n",
    "    # Input for latent space\n",
    "    noise = layers.Input(shape=(latent_dim,), name=\"noise_input\")\n",
    "    \n",
    "    # Input for conditions (normal/abnormal)\n",
    "    condition = layers.Input(shape=(1,), name=\"condition_input\")\n",
    "    \n",
    "    # Embed the condition\n",
    "    condition_embedding = layers.Embedding(2, 50)(condition)\n",
    "    condition_embedding = layers.Flatten()(condition_embedding)\n",
    "    \n",
    "    # Concatenate noise and condition\n",
    "    combined_input = layers.Concatenate()([noise, condition_embedding])\n",
    "    \n",
    "    # Dense layers\n",
    "    x = layers.Dense(256)(combined_input)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    \n",
    "    # Calculate dimensions for reshaping\n",
    "    target_height = N_MELS // 8  # 16\n",
    "    target_width = TIME_DIM // 16  # 19 for TIME_DIM=313\n",
    "    \n",
    "    x = layers.Dense(target_height * target_width * 64)(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    x = layers.Reshape((target_height, target_width, 64))(x)\n",
    "    \n",
    "    # Transposed convolution layers to upsample\n",
    "    x = layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(16, (4, 4), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(8, (4, 4), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    \n",
    "    # Ensure exact output dimensions match the input data\n",
    "    x = ExactOutputSize(N_MELS, TIME_DIM)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    # Model\n",
    "    model = models.Model([noise, condition], output, name=\"generator\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Discriminator network\n",
    "def build_discriminator():\n",
    "    \"\"\"Build discriminator network with conditional input\"\"\"\n",
    "    # Input for spectrogram with explicit shape\n",
    "    input_spec = layers.Input(shape=(N_MELS, TIME_DIM, 1), name=\"spec_input\")\n",
    "    \n",
    "    # Input for conditions (normal/abnormal)\n",
    "    condition = layers.Input(shape=(1,), name=\"condition_input\")\n",
    "    \n",
    "    # Embedding layer for condition - reshape to match input spec dimensions\n",
    "    embedding_dim = N_MELS * TIME_DIM\n",
    "    condition_embedding = layers.Embedding(2, embedding_dim)(condition)\n",
    "    condition_embedding = layers.Reshape((N_MELS, TIME_DIM, 1))(condition_embedding)\n",
    "    \n",
    "    # Concatenate inputs along the channel dimension\n",
    "    combined_input = layers.Concatenate(axis=-1)([input_spec, condition_embedding])\n",
    "    \n",
    "    # Convolutional layers with explicit padding='same' to maintain dimensions\n",
    "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same')(combined_input)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Model\n",
    "    model = models.Model([input_spec, condition], output, name=\"discriminator\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    \"\"\"Build combined GAN model\"\"\"\n",
    "    # Freeze discriminator during generator training\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    # GAN input\n",
    "    noise = layers.Input(shape=(LATENT_DIM,), name=\"gan_noise_input\")\n",
    "    condition = layers.Input(shape=(1,), name=\"gan_condition_input\")\n",
    "    \n",
    "    # Generator output\n",
    "    generated_spec = generator([noise, condition])\n",
    "    \n",
    "    # Discriminator output\n",
    "    validity = discriminator([generated_spec, condition])\n",
    "    \n",
    "    # Combined model\n",
    "    model = models.Model([noise, condition], validity, name=\"gan\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to convert spectrogram back to audio\n",
    "def spectrogram_to_audio(spectrogram):\n",
    "    \"\"\"Convert a generated spectrogram back to audio\"\"\"\n",
    "    # Remove extra dimensions and denormalize\n",
    "    spectrogram = spectrogram.squeeze()\n",
    "    \n",
    "    # Convert from dB back to power\n",
    "    S = librosa.db_to_power(spectrogram * 80 - 80)  # Rough denormalization\n",
    "    \n",
    "    # Mel spectrogram to audio using Griffin-Lim algorithm\n",
    "    y = librosa.feature.inverse.mel_to_audio(\n",
    "        S, \n",
    "        sr=SR, \n",
    "        n_fft=N_FFT, \n",
    "        hop_length=HOP_LENGTH,\n",
    "        power=2.0\n",
    "    )\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c857524-1f1f-4663-87c7-8ff1e2ab3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gan, specs, conditions, epochs, batch_size, save_interval=50):\n",
    "    \"\"\"Train the GAN model\"\"\"\n",
    "    \n",
    "    # Create folder for samples\n",
    "    os.makedirs(\"generated_samples\", exist_ok=True)\n",
    "    \n",
    "    # Get the number of total examples\n",
    "    half_batch = batch_size // 2\n",
    "    \n",
    "    # Arrays to store loss values\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        # -----------------\n",
    "        # Train Discriminator\n",
    "        # -----------------\n",
    "        \n",
    "        # Select random batch of real spectrograms\n",
    "        idx = np.random.randint(0, specs.shape[0], half_batch)\n",
    "        real_specs = specs[idx]\n",
    "        real_conditions = conditions[idx].reshape(-1, 1)\n",
    "        \n",
    "        # Generate batch of fake spectrograms\n",
    "        noise = np.random.normal(0, 1, (half_batch, LATENT_DIM))\n",
    "        fake_conditions = np.random.randint(0, 2, (half_batch, 1))\n",
    "        \n",
    "        # Generate fake spectrograms\n",
    "        fake_specs = generator.predict([noise, fake_conditions])\n",
    "        \n",
    "        # Train discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(\n",
    "            [real_specs, real_conditions], \n",
    "            np.ones((half_batch, 1))\n",
    "        )\n",
    "        d_loss_fake = discriminator.train_on_batch(\n",
    "            [fake_specs, fake_conditions], \n",
    "            np.zeros((half_batch, 1))\n",
    "        )\n",
    "        \n",
    "        # Calculate discriminator loss (taking mean of real and fake losses)\n",
    "        if isinstance(d_loss_real, list):\n",
    "            d_loss = 0.5 * (d_loss_real[0] + d_loss_fake[0])\n",
    "        else:\n",
    "            d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "        \n",
    "        # -----------------\n",
    "        # Train Generator\n",
    "        # -----------------\n",
    "        \n",
    "        # Generate new batch of noise and conditions\n",
    "        noise = np.random.normal(0, 1, (batch_size, LATENT_DIM))\n",
    "        random_conditions = np.random.randint(0, 2, (batch_size, 1))\n",
    "        \n",
    "        # Train generator (via the GAN model, where discriminator weights are frozen)\n",
    "        g_loss = gan.train_on_batch([noise, random_conditions], np.ones((batch_size, 1)))\n",
    "        \n",
    "        # Store losses\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "        \n",
    "        # Print progress - use string formatting carefully to avoid numpy format error\n",
    "        if isinstance(d_loss, np.ndarray):\n",
    "            d_loss_val = float(d_loss)\n",
    "        else:\n",
    "            d_loss_val = d_loss\n",
    "            \n",
    "        if isinstance(g_loss, np.ndarray):\n",
    "            g_loss_val = float(g_loss)\n",
    "        else:\n",
    "            g_loss_val = g_loss\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | D Loss: {d_loss_val:.4f} | G Loss: {g_loss_val:.4f}\")\n",
    "        \n",
    "        # Save generated samples\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            save_generated_samples(generator, epoch + 1)\n",
    "    \n",
    "    # Save final model\n",
    "    generator.save(\"mimii_generator.h5\")\n",
    "    discriminator.save(\"mimii_discriminator.h5\")\n",
    "    \n",
    "    # Plot loss curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(d_losses, label='Discriminator')\n",
    "    plt.plot(g_losses, label='Generator')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss_curves.png')\n",
    "    \n",
    "    return d_losses, g_losses\n",
    "\n",
    "def save_generated_samples(generator, epoch):\n",
    "    \"\"\"Save generated spectrograms and audio samples\"\"\"\n",
    "    # Generate noise and conditions\n",
    "    noise = np.random.normal(0, 1, (2, LATENT_DIM))\n",
    "    conditions = np.array([[0], [1]])  # Normal and abnormal\n",
    "    \n",
    "    # Generate spectrograms\n",
    "    gen_specs = generator.predict([noise, conditions])\n",
    "    \n",
    "    # Save spectrograms as images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(gen_specs[0, :, :, 0])\n",
    "    plt.title(\"Normal Machine Sound\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(gen_specs[1, :, :, 0])\n",
    "    plt.title(\"Abnormal Machine Sound\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"generated_samples/spectrograms_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Convert spectrograms to audio and save\n",
    "    for i, condition in enumerate([\"normal\", \"abnormal\"]):\n",
    "        audio = spectrogram_to_audio(gen_specs[i])\n",
    "        sf.write(f\"generated_samples/{condition}_epoch_{epoch}.wav\", audio, SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397bb089-f701-403f-a2ea-d0473fb0d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set path to your dataset location - updated to the root directory\n",
    "    base_dir = r\"C:\\Users\\julia\\DS4440\\machine-noise-generator\\data\"\n",
    "    \n",
    "    # Process data from all four machine types\n",
    "    machine_types = [\"fan\", \"pump\", \"slider\", \"valve\"]\n",
    "    machine_ids = [\"00\", \"02\", \"04\", \"06\"]\n",
    "    \n",
    "    # Process data\n",
    "    specs, conditions = process_mimii_dataset(base_dir, machine_types, machine_ids)\n",
    "    \n",
    "    # Build models with explicit shapes\n",
    "    generator = build_generator(LATENT_DIM)\n",
    "    discriminator = build_discriminator()\n",
    "    \n",
    "    # Print model summaries\n",
    "    print(\"\\nGenerator Summary:\")\n",
    "    generator.summary()\n",
    "    print(\"\\nDiscriminator Summary:\")\n",
    "    discriminator.summary()\n",
    "    \n",
    "    # Test the generator to verify output shape\n",
    "    noise = np.random.normal(0, 1, (1, LATENT_DIM))\n",
    "    condition = np.array([[0]])  # Normal condition\n",
    "    test_output = generator.predict([noise, condition])\n",
    "    print(f\"Generator test output shape: {test_output.shape}\")\n",
    "    \n",
    "    # Test the discriminator to verify it accepts the generator's output\n",
    "    disc_output = discriminator.predict([test_output, condition])\n",
    "    print(f\"Discriminator test output shape with generator output: {disc_output.shape}\")\n",
    "    \n",
    "    # Build GAN\n",
    "    gan = build_gan(generator, discriminator)\n",
    "    \n",
    "    # Compile models with lower learning rates\n",
    "    discriminator.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    gan.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5),\n",
    "        loss='binary_crossentropy'\n",
    "    )\n",
    "    \n",
    "    # Start with short training\n",
    "    short_epochs = 5\n",
    "    try:\n",
    "        print(\"Starting short training run...\")\n",
    "        train_gan(generator, discriminator, gan, specs, conditions, short_epochs, BATCH_SIZE)\n",
    "        \n",
    "        print(\"Short training successful! Now starting full training...\")\n",
    "        # If short training works, continue with full training\n",
    "        full_epochs = EPOCHS\n",
    "        train_gan(generator, discriminator, gan, specs, conditions, full_epochs, BATCH_SIZE)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {str(e)}\")\n",
    "        # Print detailed error info\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64a35a7-6d18-4218-aa77-83ded94afba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing fan data...\n",
      "Processing 30 normal files for fan id_00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]C:\\Users\\julia\\anaconda3\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "C:\\Users\\julia\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\julia\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:04<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 normal files for fan id_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 52.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 normal files for fan id_04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 52.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 normal files for fan id_06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 56.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 abnormal files for fan id_00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 57.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 abnormal files for fan id_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 56.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 abnormal files for fan id_04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 55.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 abnormal files for fan id_06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 53.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing pump data...\n",
      "Processing 30 normal files for pump id_00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▌                                                                             | 2/30 [00:00<00:01, 23.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m machine_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m02\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m04\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m06\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Process data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m specs, conditions \u001b[38;5;241m=\u001b[39m process_mimii_dataset(base_dir, machine_types, machine_ids)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Build models with explicit shapes\u001b[39;00m\n\u001b[0;32m     13\u001b[0m generator \u001b[38;5;241m=\u001b[39m build_generator(LATENT_DIM)\n",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m, in \u001b[0;36mprocess_mimii_dataset\u001b[1;34m(base_dir, machine_types, machine_ids)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m tqdm(normal_files[:\u001b[38;5;241m50\u001b[39m]):  \u001b[38;5;66;03m# Limit to 50 files per ID for faster processing\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m         spec, condition \u001b[38;5;241m=\u001b[39m load_and_preprocess_audio(file_path, is_abnormal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     69\u001b[0m         specs\u001b[38;5;241m.\u001b[39mappend(spec)\n\u001b[0;32m     70\u001b[0m         conditions\u001b[38;5;241m.\u001b[39mappend(condition)\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36mload_and_preprocess_audio\u001b[1;34m(file_path, is_abnormal)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio file and convert to mel spectrogram\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load audio file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m audio, _ \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(file_path, sr\u001b[38;5;241m=\u001b[39mSR, duration\u001b[38;5;241m=\u001b[39mAUDIO_LENGTH)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Pad if needed\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(audio) \u001b[38;5;241m<\u001b[39m SR \u001b[38;5;241m*\u001b[39m AUDIO_LENGTH:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    206\u001b[0m     context \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n\u001b[0;32m    212\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m sf_desc\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bitrate_mode \u001b[38;5;241m=\u001b[39m bitrate_mode\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:1254\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1252\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m             file \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mencode(_sys\u001b[38;5;241m.\u001b[39mgetfilesystemencoding())\n\u001b[1;32m-> 1254\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m openfunction(file, mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info)\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1256\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_fd(file, mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, closefd)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3c719-7a21-458f-8914-925d9b89d87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
